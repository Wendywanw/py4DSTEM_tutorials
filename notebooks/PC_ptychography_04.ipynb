{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff5586b0-2375-4645-b70c-73691a9fa53d",
   "metadata": {},
   "source": [
    "# Ptychography Tutorial 04\n",
    "\n",
    "This is the fourth tutorial notebook in the iterative ptychography series.  \n",
    "In this tutorial notebook we will cover:\n",
    "- GPU memory-management for ptychographic reconstructions\n",
    "\n",
    "### Downloads\n",
    "This tutorial uses the following datasets:\n",
    "- [ptycho_ducky_simulation_01.h5](https://drive.google.com/file/d/1VtYVHWiuI8AT0yucaylIcQQJ_px79ash/view?usp=drive_link)\n",
    "- [ptycho_ducky_vacuum-probe_01.h5](https://drive.google.com/file/d/1CeVGVvMf2QeJK1ADQ9MBK308NhvoVaVn/view?usp=drive_link)\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "This tutorial was created by the py4DSTEM `phase_contrast` team:\n",
    "- Georgios Varnavides (gvarnavides@berkeley.edu)\n",
    "- Stephanie Ribet (sribet@lbl.gov)\n",
    "- Colin Ophus (clophus@lbl.gov)\n",
    "\n",
    "Last updated: 2024 May 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c213cb-bc06-44b4-9c20-688763e2750a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ptychographic reconstructions can be very computationally expensive. py4DSTEM offers single-node GPU acceleration to speed up these calculations.\n",
    "\n",
    "GPU calculations however, are often VRAM (memory) limited. Here, we investigate various flags as well as tips and tricks to enable efficient GPU memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4b2849-740e-4175-bfe3-0b60f04fe15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cupyx.jit.rawkernel is experimental. The interface can change in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.18\n",
      "13.4.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import py4DSTEM\n",
    "\n",
    "from py4DSTEM.process.phase.utils import get_array_module\n",
    "from cupy.fft.config import get_plan_cache\n",
    "\n",
    "print(py4DSTEM.__version__)\n",
    "print(cp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66582ca0-0f80-4df2-8151-aa6e357f3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'C:\\\\github\\\\py4DSTEM_tutorials\\\\data\\\\'\n",
    "# file_data = file_path + 'ptycho_ducky_simulation_03.h5'\n",
    "# file_probe = file_path + 'ptycho_ducky_vacuum-probe_03.h5'\n",
    "\n",
    "# probe = py4DSTEM.read(file_probe)\n",
    "# dataset = py4DSTEM.read(file_data)\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6da3dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\_Data\\\\wendy_data\\\\'\n",
    "file_data = path + 'processed_al_alo_2_03_masked.h5'\n",
    "probe_path = path + 'processed_al_alo_2_12_master.h5'\n",
    "pt = path + 'pt_02_master.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a1bf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = py4DSTEM.read(file_data)\n",
    "probe = py4DSTEM.read(probe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17613520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCube( A 4-dimensional array of shape (16, 16, 192, 192) called 'datacube',\n",
       "          with dimensions:\n",
       "\n",
       "              Rx = [0.0,0.34555085515441486,0.6911017103088297,...] A\n",
       "              Ry = [0.0,0.34555085515441486,0.6911017103088297,...] A\n",
       "              Qx = [0.0,0.45449762893741413,0.9089952578748283,...] mrad\n",
       "              Qy = [0.0,0.45449762893741413,0.9089952578748283,...] mrad\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b470169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VirtualDiffraction( A 2-dimensional array of shape (192, 192) called 'dp_mean',\n",
       "                    with dimensions:\n",
       "\n",
       "                        dim0 = [0,1,2,...] pixels\n",
       "                        dim1 = [0,1,2,...] pixels\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probe.get_dp_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5eb1f-a039-415b-b354-0120a4fcce3b",
   "metadata": {},
   "source": [
    "### GPU Memory Usage\n",
    "\n",
    "First, let's define two helper functions to:  \n",
    "- clear a class's cupy arrays\n",
    "- report class GPU memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2978732-4a12-43ce-aaf2-b4483f96e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "from cupy.fft.config import get_plan_cache\n",
    "mempool = cp.get_default_memory_pool()\n",
    "pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "cache = get_plan_cache()\n",
    "\n",
    "def report_class_gpu_memory_usage(cls):\n",
    "\n",
    "    size_on_device = 0\n",
    "    for att in sorted(cls.__dict__):\n",
    "        attr = getattr(cls,att)\n",
    "        \n",
    "        if isinstance(attr,(np.ndarray,cp.ndarray)):\n",
    "            \n",
    "            if get_array_module(attr) is not np:\n",
    "                size_on_device += attr.nbytes\n",
    "                print(f\"Attribute {att}: {attr.nbytes*1e-3:.3f}Kb\")\n",
    "    \n",
    "        if isinstance(attr,list) and isinstance(attr[0],(np.ndarray,cp.ndarray)):\n",
    "            \n",
    "            size_entering_loop = size_on_device\n",
    "            for el in attr:\n",
    "                if get_array_module(el) is not np:\n",
    "                    size_on_device += el.nbytes\n",
    "                    \n",
    "            print(f\"Attribute {att}: {(size_on_device-size_entering_loop)*1e-3:.3f}Kb\")\n",
    "    \n",
    "    print(f\"\\nEstimated size on device: {size_on_device*1e-6:.3f}Mb\")\n",
    "    print(f\"Reported size on device: {mempool.used_bytes()*1e-6:.3f}Mb\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def release_class_gpu_memory(clear_fft_cache = True):\n",
    "\n",
    "    if clear_fft_cache is True:\n",
    "        cache.clear()\n",
    "        \n",
    "    mempool.free_all_blocks()\n",
    "    pinned_mempool.free_all_blocks()\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c5a642-ec81-4d1e-a399-2168e7915c5a",
   "metadata": {},
   "source": [
    "### CPU-only calculation\n",
    "\n",
    "To estabish a baseline, we perform a CPU-only calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e071f06-509e-4bcd-b8ab-55f575457cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating center of mass: 100%|██████████| 65536/65536 [00:05<00:00, 11237.46probe position/s]\n",
      "Best fit rotation = -4 degrees.\n",
      "Normalizing amplitudes: 100%|██████████| 65536/65536 [03:07<00:00, 349.99probe position/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated size on device: 0.000Mb\n",
      "Reported size on device: 0.000Mb\n"
     ]
    }
   ],
   "source": [
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=300e3, \n",
    "    defocus=0, \n",
    "    vacuum_probe_intensity=probe.tree('dp_mean').data,\n",
    "    verbose = True,\n",
    "    device='cpu', # default\n",
    "    # storage = 'cpu',\n",
    ").preprocess(\n",
    "    plot_rotation=False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    "    store_initial_arrays= False, # don't store arrays necessary for reset=True\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224edfb6-1ed5-44cf-9d38-d2331507aeea",
   "metadata": {},
   "source": [
    "As expected, preprocessing with `device='cpu'` uses no GPU memory.  \n",
    "Also notice two additional flags to help with memory issues:\n",
    "- `vectorized_com_calculation=False` &rarr; computes the otherwise memory-expensive CoM calculation using a for-loop\n",
    "- `store_initial_arrays=False` &rarr; doesn't store the arrays necessary to restart the calculation\n",
    "\n",
    "`reconstruct` will similarly work directly on the CPU and use no GPU memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5fd59e20-927b-446e-ad92-90df37aaeaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing 2 iterations using a complex object type, with the gradient-descent algorithm, with normalization_min: 1 and step_size: 0.5, in batches of max 512 measurements.\n",
      "Reconstructing object and probe: 100%|██████████| 2/2 [19:33<00:00, 586.63s/ iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated size on device: 0.000Mb\n",
      "Reported size on device: 0.000Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ptycho = ptycho.reconstruct(\n",
    "    seed_random=0, \n",
    "    num_iter = 2,\n",
    "    max_batch_size=512,\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13d8107-ac11-4485-b68c-6ee89a224d8f",
   "metadata": {},
   "source": [
    "### Expensive calculations on GPU\n",
    "\n",
    "The next step is to store the 4D-data and other necessary utility arrays on the CPU, but perform the actual computations on the GPU by \"streaming\" the necessary data inside the loop. This can be enabled by specifying `device='gpu'` and `storage='cpu'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b4d0710e-2795-494d-ad8c-523755379f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute _known_aberrations_array: 294.912Kb\n",
      "Attribute _object: 2967.048Kb\n",
      "Attribute _probe: 294.912Kb\n",
      "\n",
      "Estimated size on device: 3.557Mb\n",
      "Reported size on device: 3.557Mb\n"
     ]
    }
   ],
   "source": [
    "ptycho = None\n",
    "release_class_gpu_memory()\n",
    "\n",
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=300e3, \n",
    "    defocus=0, \n",
    "    vacuum_probe_intensity=probe.tree('dp_mean').data,\n",
    "    verbose = False,\n",
    "    device='gpu', # perform calculations on the GPU\n",
    "    storage='cpu', # store data and other utility arrays on CPU\n",
    ").preprocess(\n",
    "    plot_rotation=False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    "    store_initial_arrays= False, # don't store arrays necessary for reset=True\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61370319-1f15-4b47-bae4-be0f47287414",
   "metadata": {},
   "source": [
    "As we can see this only stores the minimum necessary arrays on the GPU (notably the object and probe arrays), and releases all other intermediate memory after execution (seen by the estimated size above matches the reported size by cupy).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3760a361-b8eb-44c8-860b-fcae141aa386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing object and probe: 100%|██████████| 2/2 [00:14<00:00,  7.30s/ iter]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute _known_aberrations_array: 294.912Kb\n",
      "Attribute _object: 2967.048Kb\n",
      "Attribute _probe: 294.912Kb\n",
      "\n",
      "Estimated size on device: 3.557Mb\n",
      "Reported size on device: 3.557Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ptycho = ptycho.reconstruct(\n",
    "    seed_random=0, \n",
    "    num_iter = 2,\n",
    "    max_batch_size=512,\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b86008-4671-43f8-af37-6634e1ffaaee",
   "metadata": {},
   "source": [
    "### FFT Caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f035cb-dec8-4cd4-8d48-7c07ca979326",
   "metadata": {},
   "source": [
    "In addition to intermediate arrays which are deallocated and cleared above, the other big culprit in the GPU storing more arrays than presumably requested is cupy's default FFT plan caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "824ecb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "probe_ndarray = probe.tree('dp_mean').data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10c7f500-5cf5-49b5-b644-1cf65ed07aab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m ptycho = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      2\u001b[39m release_class_gpu_memory(clear_fft_cache=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n\u001b[32m      5\u001b[39m     datacube=dataset, \n\u001b[32m      6\u001b[39m     energy=\u001b[32m300e3\u001b[39m, \n\u001b[32m      7\u001b[39m     defocus=\u001b[32m0\u001b[39m, \n\u001b[32m      8\u001b[39m     vacuum_probe_intensity=probe_ndarray,\n\u001b[32m      9\u001b[39m     verbose = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     10\u001b[39m     device=\u001b[33m'\u001b[39m\u001b[33mgpu\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# perform calculations on the GPU\u001b[39;00m\n\u001b[32m     11\u001b[39m     storage=\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# store data and other utility arrays on CPU\u001b[39;00m\n\u001b[32m     12\u001b[39m     clear_fft_cache = \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# don't clear FFT cache at the end\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m ).preprocess(\n\u001b[32m     14\u001b[39m     plot_rotation = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     15\u001b[39m     plot_center_of_mass = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     16\u001b[39m     plot_probe_overlaps = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     17\u001b[39m     vectorized_com_calculation = \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# disable default CoM vectorized calc\u001b[39;00m\n\u001b[32m     18\u001b[39m     store_initial_arrays = \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# don't store arrays necessary for reset=True\u001b[39;00m\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m report_class_gpu_memory_usage(ptycho)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\slab\\Anaconda3\\envs\\py4dstem\\Lib\\site-packages\\py4DSTEM\\process\\phase\\singleslice_ptychography.py:416\u001b[39m, in \u001b[36mSingleslicePtychography.preprocess\u001b[39m\u001b[34m(self, diffraction_intensities_shape, reshaping_method, shifting_interpolation_order, padded_diffraction_intensities_shape, region_of_interest_shape, dp_mask, in_place_datacube_modification, fit_function, plot_center_of_mass, plot_rotation, maximize_divergence, rotation_angles_deg, plot_probe_overlaps, force_com_rotation, force_com_transpose, force_com_shifts, force_com_measured, vectorized_com_calculation, force_scan_sampling, force_angular_sampling, force_reciprocal_sampling, object_fov_mask, crop_patterns, center_positions_in_fov, store_initial_arrays, device, clear_fft_cache, max_batch_size, **kwargs)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28mself\u001b[39m.copy_attributes_to_device(attrs, storage)\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# corner-center amplitudes\u001b[39;00m\n\u001b[32m    411\u001b[39m (\n\u001b[32m    412\u001b[39m     \u001b[38;5;28mself\u001b[39m._amplitudes,\n\u001b[32m    413\u001b[39m     \u001b[38;5;28mself\u001b[39m._mean_diffraction_intensity,\n\u001b[32m    414\u001b[39m     \u001b[38;5;28mself\u001b[39m._crop_mask,\n\u001b[32m    415\u001b[39m     \u001b[38;5;28mself\u001b[39m._crop_mask_shape,\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m ) = \u001b[38;5;28mself\u001b[39m._normalize_diffraction_intensities(\n\u001b[32m    417\u001b[39m     _intensities,\n\u001b[32m    418\u001b[39m     \u001b[38;5;28mself\u001b[39m._com_fitted_x,\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m._com_fitted_y,\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m._positions_mask,\n\u001b[32m    421\u001b[39m     crop_patterns,\n\u001b[32m    422\u001b[39m     in_place_datacube_modification,\n\u001b[32m    423\u001b[39m     shifting_interpolation_order=shifting_interpolation_order,\n\u001b[32m    424\u001b[39m )\n\u001b[32m    426\u001b[39m \u001b[38;5;66;03m# explicitly transfer arrays to storage\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_place_datacube_modification:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\slab\\Anaconda3\\envs\\py4dstem\\Lib\\site-packages\\py4DSTEM\\process\\phase\\phase_base_class.py:1452\u001b[39m, in \u001b[36mPhaseReconstruction._normalize_diffraction_intensities\u001b[39m\u001b[34m(self, diffraction_intensities, com_fitted_x, com_fitted_y, positions_mask, crop_patterns, in_place_datacube_modification, shifting_interpolation_order, return_intensities_instead)\u001b[39m\n\u001b[32m   1444\u001b[39m     intensities = get_shifted_ar(\n\u001b[32m   1445\u001b[39m         diff_intensities[rx, ry].astype(np.float32),\n\u001b[32m   1446\u001b[39m         -com_fitted_x[rx, ry],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1449\u001b[39m         device=\u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1450\u001b[39m     )\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1452\u001b[39m     intensities = shift(\n\u001b[32m   1453\u001b[39m         diff_intensities[rx, ry].astype(np.float32),\n\u001b[32m   1454\u001b[39m         (-com_fitted_x[rx, ry], -com_fitted_y[rx, ry]),\n\u001b[32m   1455\u001b[39m         order=shifting_interpolation_order,\n\u001b[32m   1456\u001b[39m         mode=\u001b[33m\"\u001b[39m\u001b[33mgrid-wrap\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1457\u001b[39m     )\n\u001b[32m   1459\u001b[39m mean_intensity += np.sum(intensities)\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_intensities_instead:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\slab\\Anaconda3\\envs\\py4dstem\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:734\u001b[39m, in \u001b[36mshift\u001b[39m\u001b[34m(input, shift, output, order, mode, cval, prefilter)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shift.flags.contiguous:\n\u001b[32m    733\u001b[39m     shift = shift.copy()\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m _nd_image.zoom_shift(filtered, \u001b[38;5;28;01mNone\u001b[39;00m, shift, output, order, mode, cval,\n\u001b[32m    735\u001b[39m                      npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ptycho = None\n",
    "release_class_gpu_memory(clear_fft_cache=False)\n",
    "\n",
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=300e3, \n",
    "    defocus=0, \n",
    "    vacuum_probe_intensity=probe_ndarray,\n",
    "    verbose = False,\n",
    "    device='gpu', # perform calculations on the GPU\n",
    "    storage='cpu', # store data and other utility arrays on CPU\n",
    "    clear_fft_cache = False, # don't clear FFT cache at the end\n",
    ").preprocess(\n",
    "    plot_rotation = False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    "    store_initial_arrays = False, # don't store arrays necessary for reset=True\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c729712d-337e-4b7c-838b-3ef6dbafe98c",
   "metadata": {},
   "source": [
    "Notice that when we don't specify `clear_fft_cache=True` (on by default), the GPU reports some additional memory usage. These are the cached FFT plans, which you can inspect as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eeadbd-66f0-4970-8650-175f892cb6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- cuFFT plan cache (device 0) -------------------\n",
      "cache enabled? True\n",
      "current / max size   : 2 / 16 (counts)\n",
      "current / max memsize: 0 / (unlimited) (bytes)\n",
      "hits / misses: 2 / 2 (counts)\n",
      "\n",
      "cached plans (most recently used first):\n",
      "key: ((200, 200), (200, 200), 1, 40000, (200, 200), 1, 40000, 41, 1681, 'C', 2, None), plan type: PlanNd, memory usage: 0\n",
      "key: ((200, 200), (200, 200), 1, 1, (200, 200), 1, 1, 41, 1, 'C', 1, None), plan type: PlanNd, memory usage: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cache.show_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611379bc-bffd-43b1-94bb-6836eb4da808",
   "metadata": {},
   "source": [
    "By default, we enable cupy's default FFT plan caching within each function call (since it is quite performant), but clear the cache at the end of `preprocess`, `reconstruct`, and `visualize`. An even more aggresive solution to allow better memory management still is to limit the cache size, or disable it completely (by specifying a size of zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d65acb-7695-43e9-9993-1aaa813435ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing object and probe: 100%|██████████| 2/2 [00:00<00:00,  4.13 iter/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute _known_aberrations_array: 320.000Kb\n",
      "Attribute _object: 11139.200Kb\n",
      "Attribute _probe: 320.000Kb\n",
      "\n",
      "Estimated size on device: 11.779Mb\n",
      "Reported size on device: 11.780Mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cache.set_size(0)\n",
    "\n",
    "ptycho = None\n",
    "release_class_gpu_memory()\n",
    "\n",
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=80e3, \n",
    "    defocus=500, \n",
    "    vacuum_probe_intensity=probe_ndarray,\n",
    "    verbose = False,\n",
    "    device='gpu', # perform calculations on the GPU\n",
    "    storage='cpu', # store data and other utility arrays on CPU\n",
    "    clear_fft_cache=False, # for demonstration purposes that cache is not used\n",
    ").preprocess(\n",
    "    plot_rotation=False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    "    store_initial_arrays= False, # don't store arrays necessary for reset=True\n",
    ").reconstruct(\n",
    "    seed_random=0, \n",
    "    num_iter = 2,\n",
    "    max_batch_size=512,\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acfab843-750e-4dfb-8fdf-5f4b37100325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- cuFFT plan cache (device 0) -------------------\n",
      "cache enabled? False\n",
      "current / max size   : 0 / 0 (counts)\n",
      "current / max memsize: 0 / (unlimited) (bytes)\n",
      "hits / misses: 0 / 0 (counts)\n",
      "\n",
      "cached plans (most recently used first):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cache.show_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe39ff8-df39-42bc-9cb0-013e606f0648",
   "metadata": {},
   "source": [
    "### Store/compute all arrays on GPU  \n",
    "If memory is not a concern, then you can skip the `storage='cpu'` flag and store all arrays on the GPU for the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67e50f87-704a-4cab-95a6-9ea8d75c0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing object and probe: 100%|██████████| 2/2 [00:00<00:00,  4.52 iter/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute _amplitudes: 268960.000Kb\n",
      "Attribute _com_fitted_x: 6.724Kb\n",
      "Attribute _com_fitted_y: 6.724Kb\n",
      "Attribute _com_measured_x: 6.724Kb\n",
      "Attribute _com_measured_y: 6.724Kb\n",
      "Attribute _com_normalized_x: 6.724Kb\n",
      "Attribute _com_normalized_y: 6.724Kb\n",
      "Attribute _com_x: 6.724Kb\n",
      "Attribute _com_y: 6.724Kb\n",
      "Attribute _known_aberrations_array: 320.000Kb\n",
      "Attribute _object: 11139.200Kb\n",
      "Attribute _positions_initial: 13.448Kb\n",
      "Attribute _positions_px: 13.448Kb\n",
      "Attribute _positions_px_initial: 13.448Kb\n",
      "Attribute _positions_px_initial_com: 0.008Kb\n",
      "Attribute _probe: 320.000Kb\n",
      "\n",
      "Estimated size on device: 280.833Mb\n",
      "Reported size on device: 280.839Mb\n"
     ]
    }
   ],
   "source": [
    "cache.set_size(16) # restore to default caching\n",
    "\n",
    "ptycho = None\n",
    "release_class_gpu_memory()\n",
    "\n",
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=80e3, \n",
    "    defocus=500, \n",
    "    vacuum_probe_intensity=probe.data,\n",
    "    verbose = False,\n",
    "    device='gpu', # perform calculations on the GPU\n",
    "    storage='gpu', # can be omited, defaults to 'device'\n",
    ").preprocess(\n",
    "    plot_rotation=False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    "    store_initial_arrays= False, # don't store arrays necessary for reset=True\n",
    ").reconstruct(\n",
    "    seed_random=0, \n",
    "    num_iter = 2,\n",
    "    max_batch_size=512,\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed88b70b-d81f-418a-a2a2-49fa934eafc1",
   "metadata": {},
   "source": [
    "Notice this reports a lot more arrays on the GPU, notably the amplitude data itself - which can be quite large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd09155-9527-4bf9-9b60-fef53d8a1470",
   "metadata": {},
   "source": [
    "### Function-specific `device`\n",
    "\n",
    "Note that you can overwrite the top-level `device` and `clear_fft_cache` attributes set at initialization during each subsequent function call, meaning you can e.g. preprocess your data on the 'cpu' and reconstruct on the 'gpu':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cdb78f8-6b27-4828-9f60-843436f914db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reconstructing object and probe: 100%|██████████| 2/2 [00:04<00:00,  2.34s/ iter]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute _known_aberrations_array: 320.000Kb\n",
      "Attribute _object: 11139.200Kb\n",
      "Attribute _object_initial: 11139.200Kb\n",
      "Attribute _probe: 640.000Kb\n",
      "Attribute _probe_initial: 640.000Kb\n",
      "Attribute _probe_initial_aperture: 320.000Kb\n",
      "\n",
      "Estimated size on device: 24.198Mb\n",
      "Reported size on device: 24.199Mb\n"
     ]
    }
   ],
   "source": [
    "ptycho = None\n",
    "release_class_gpu_memory()\n",
    "\n",
    "ptycho = py4DSTEM.process.phase.SingleslicePtychography(\n",
    "    datacube=dataset, \n",
    "    energy=80e3, \n",
    "    defocus=500, \n",
    "    vacuum_probe_intensity=probe.data,\n",
    "    verbose = False,\n",
    "    device='cpu', # preprocess on the CPU\n",
    ").preprocess(\n",
    "    plot_rotation=False,\n",
    "    plot_center_of_mass = False,\n",
    "    plot_probe_overlaps = False,\n",
    "    vectorized_com_calculation = False, # disable default CoM vectorized calc\n",
    ").reconstruct(\n",
    "    seed_random=0, \n",
    "    num_iter = 2,\n",
    "    max_batch_size=512,\n",
    "    device='gpu', # reconstruct on the GPU\n",
    ")\n",
    "\n",
    "report_class_gpu_memory_usage(ptycho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38e0bfe-7b48-4b80-bef6-61269055061f",
   "metadata": {},
   "source": [
    "### `max_batch_size`\n",
    "\n",
    "Finally, you can use the `max_batch_size` in both `preprocess` and `reconstruct` to ensure the number of probe-positions streamed to `device` at any given iteration is kept small-enough for your GPU memory to handle.\n",
    "\n",
    "Note: this option currently defaults to \"mini-batch\" behaviour in stochastic gradient descent, meaning the object and probes will be updated per batch, not per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604fcf8-5a66-42ee-8384-5303b4081e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py4dstem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
